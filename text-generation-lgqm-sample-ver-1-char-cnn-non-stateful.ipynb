{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver 1 using char-cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import TimeDistributed, Activation\n",
    "from numpy.random import choice\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\n",
    "from keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.regularizers import l2, activity_l2, l1, activity_l1\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils.layer_utils import layer_from_config\n",
    "from keras.metrics import categorical_crossentropy, categorical_accuracy\n",
    "from keras.layers.convolutional import *\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from numpy.random import choice\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = open('./data/lgqm-sample.txt').read()\n",
    "text = unicode(text, \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text:  35397 《临高启明》吹牛者\r\n",
      "\r\n",
      "严正声明：本书为丫丫小说网(www.shuyaya.com)的用户上传至其在本站的存储空间，本站只提供TXT全集电子书存储服务以及免费下载服务，以下作品内容之版权与本站无任何\n"
     ]
    }
   ],
   "source": [
    "print('length of text: ', len(text), text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "charset = set(text)\n",
    "char_freq_map = {c: 0 for c in charset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in text:\n",
    "    char_freq_map[c] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of charset 2064 [u' ', u'\\uff0c', u'\\u7684', u'\\r', u'\\n', u'\\u3002', u'\\u662f', u'\\u4e00', u'\\u4e0d', u'\\u4e86', u'\\u8fd9', u'\\u4eba', u'\\u4e2a', u'\\u201c', u'\\u201d', u'\\u5b50', u'\\u6709', u'\\u6765', u'\\u4ed6', u'\\u5728', u'\\u9ad8', u'\\u5927', u'\\u4e5f', u'\\u4eec', u'\\u91cc', u'\\u4e0a', u'\\u90fd', u'\\u8001', u'\\u8fc7', u'\\u5230', u'\\u5f97', u'\\u5c31', u'\\u8bf4', u'\\u591a', u'\\u7237', u'\\u4e0b', u'\\u4f1a', u'\\u4e4b', u'\\u6d77', u'\\u6587']\n"
     ]
    }
   ],
   "source": [
    "char_freq_list = sorted(char_freq_map.items(), key=operator.itemgetter(1))\n",
    "char_freq_list.reverse()\n",
    "charlist = [pair[0] for pair in char_freq_list]\n",
    "print('size of charset', len(charlist), charlist[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char2idx = dict((c, i) for i, c in enumerate(charlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_in_idx = [char2idx[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《临高启明》吹牛者\r\n",
      "\r\n",
      "严正声明：本书为丫丫小\n"
     ]
    }
   ],
   "source": [
    "#text_in_idx[:6]\n",
    "print(''.join(charlist[i] for i in text_in_idx[:24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 35349\n"
     ]
    }
   ],
   "source": [
    "maxlen = 48\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text_in_idx) - maxlen):\n",
    "    sentences.append(text_in_idx[i: i + maxlen])\n",
    "    next_chars.append(text_in_idx[i+1: i+maxlen+1])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35349, 48), (35349, 48))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = np.array(sentences)\n",
    "next_chars = np.array(next_chars)\n",
    "sentences.shape, next_chars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_fac = 200\n",
    "batch_size = 64\n",
    "n_hidden = 512\n",
    "vocab_size = len(charlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stateless with batch\n",
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=maxlen, batch_input_shape=(batch_size, maxlen)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(n_hidden, input_dim=n_fac,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        LSTM(n_hidden, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(n_hidden, activation='relu')),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n",
    "# non-stateful?\n",
    "# model=Sequential([\n",
    "#         Embedding(vocab_size, n_fac, input_length=maxlen),\n",
    "#         BatchNormalization(),\n",
    "#         LSTM(n_hidden, input_dim=n_fac,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "#              consume_less='gpu'),\n",
    "#         Dropout(0.2),\n",
    "#         LSTM(n_hidden, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "#              consume_less='gpu'),\n",
    "#         Dropout(0.2),\n",
    "#         TimeDistributed(Dense(vocab_size)),\n",
    "#         Dropout(0.2),\n",
    "#         TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "#     ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (64, 48, 200)         412800      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNormal(64, 48, 200)         400         embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (64, 48, 512)         1460224     batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (64, 48, 512)         0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (64, 48, 512)         2099200     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (64, 48, 512)         0           lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribute(64, 48, 512)         262656      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (64, 48, 512)         0           timedistributed_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_2 (TimeDistribute(64, 48, 2064)        1058832     dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5294112\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epochs(n):\n",
    "    # input must be exact multiples of batch_size, for stateful\n",
    "    multiples = len(sentences)//batch_size*batch_size\n",
    "    sentences_truncated = sentences[:multiples]\n",
    "    next_chars_truncated = next_chars[:multiples]\n",
    "    next_chars_adjusted = np.expand_dims(next_chars_truncated,-1)\n",
    "    for i in range(n):\n",
    "        model.reset_states()\n",
    "        h = model.fit(sentences_truncated, next_chars_adjusted, batch_size=batch_size, nb_epoch=1, shuffle=True)\n",
    "        print(h.history, h.history['loss'])\n",
    "        weight_file_name = './data/text-generation-lgqm-ver-1-char-cnn-'+str(time.time())+'.h5'\n",
    "        model.save_weights(weight_file_name)\n",
    "        print('saved weights: ', weight_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: when cr is not together with lf, a line is biten! But, I doubt it ever happens in original text\n",
    "# Better learn more to let it avoid naturally\n",
    "\n",
    "def print_example_inline_seed_non_stateful():\n",
    "    pre_string = u\"第65535节 \"\n",
    "    \n",
    "    rand_idx = np.random.randint(0, high=len(text)-maxlen-1)\n",
    "    seed_string = text[rand_idx:rand_idx+maxlen]\n",
    "    \n",
    "    for i in range(maxlen+1):\n",
    "        x=np.array([char2idx[c] for c in seed_string[-maxlen:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(charlist, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    seed_string = pre_string+seed_string[maxlen:]\n",
    "    print(seed_string)\n",
    "    for i in range(800):\n",
    "        x=np.array([char2idx[c] for c in seed_string[-maxlen:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(charlist, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print('final: ', seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01\n",
    "# model.load_weights('./data/text-generation-lgqm-ver-1-char-cnn-1497597351.55.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "35328/35328 [==============================] - 161s - loss: 1.2177   \n",
      "{'loss': [1.2177366734198902]} [1.2177366734198902]\n",
      "saved weights:  ./data/text-generation-lgqm-ver-1-char-cnn-1497598592.5.h5\n"
     ]
    }
   ],
   "source": [
    "run_epochs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第65535节 记不清了――他照旧属于要庆祝11.11的那伙人。[搜索最新更新尽在]\n",
      "\n",
      "    一伙古装的士兵\n",
      "final:  第65535节 记不清了――他照旧属于要庆祝11.11的那伙人。[搜索最新更新尽在]\n",
      "\n",
      "    一伙古装的士兵，在骑马的军官带领下，把十多个乡民模样的衣服。文总也算是经过些风月场面的人物。\n",
      "\n",
      "    管事领着家丁们从栈房院子里搬来搬。萧子山不由得哑然一笑，这年头的看着他们。\n",
      "\n",
      "    “子山。一会我发这几个倭人把你吓得心里做？”萧子山严重的表示置疑。\n",
      "\n",
      "    至于钱，虽然他们心中揣度。莫非是日本国内哪位名主地使者？转念一想。倭人自己日用尚且不足。百货十多少白银的收购了许多大小款式不一的镜子、一次性打火机、各种磨砂、喷花的玻璃杯，居然惨败！文不及这几个孩子又是能吃的时候，一家人靠七钱银子开销，着实有点吃力。\n",
      "\n",
      "    临走之前，文德嗣留下二百两银子，要高老爷在临近购置疑。[搜索最新更新尽在]\n",
      "\n",
      "    临高就成了最好的选择，他们拒绝了更省油的电喷引擎的新款，买了一辆老款的切诺基吉普：四驱的手推车。\n",
      "\n",
      "    议会民主？三权分立？君主立宪？集权主义？民族主义？社会主义？社会主义？社会主义？[搜索最新更新尽在]\n",
      "\n",
      "    虽然文德嗣也在网络上看过一些相当血淋淋的照片。血肉模糊的无头尸体在900万像素，单反镜头的演绎下逼真得让人想吐。\n",
      "\n",
      "    萧子山毕业以后，在珠三角的几家企业都呆过，上过黑心老板的当，做过不切实际的梦，最后好歹在一家外企的找了份待遇还不错的工作，勤勤恳恳的干活拿工资――也许多所老爷的脸色，连平日里最得宠的小妾，都懒得临幸了。\n",
      "\n",
      "    传统穿越暴利神器玻璃杯，居然惨败！一千两成了一两，这个落差也是在太大了，钻石变成了玻璃。\n",
      "\n",
      "    玻璃杯，每个一两。\n",
      "\n",
      "第八点m/\n",
      "    “对，很有可能。”\n",
      "\n",
      "    “是啊，这才是男人的天堂啊！”\n",
      "\n",
      "    货款按他们谈好的价格，结算下来，共得白银三千多两白银，其中几面全身穿衣镜，看得高老爷眼睛都快掉下来了。\n",
      "\n",
      "    “不过，敝人倒是另有一个主意……”三个人吃了一惊，欠起\n"
     ]
    }
   ],
   "source": [
    "print_example_inline_seed_non_stateful()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(6):\n",
    "#     run_epochs(20)\n",
    "#     print_example_inline_seed_non_stateful()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text:  9215340 《临高启明》吹牛者\n",
      "\n",
      "严正声明：本书为丫丫小说网(www.shuyaya.com)的用户上传至其在本站的存储空间，本站只提供TXT全集电子书存储服务以及免费下载服务，以下作品内容之版权与本站无任何\n",
      "size of charset 5688\n",
      " \n",
      "，\n",
      "的\n",
      "\n",
      "\n",
      "\n",
      "。\n",
      "是\n",
      "了\n",
      "一\n",
      "不\n",
      "“\n",
      "”\n",
      "这\n",
      "人\n",
      "有\n",
      "在\n",
      "他\n",
      "来\n",
      "个\n",
      "大\n",
      "上\n",
      "就\n",
      "得\n",
      "到\n",
      "要\n",
      "们\n",
      "和\n",
      "说\n",
      "里\n",
      "―\n",
      "也\n",
      "着\n",
      "子\n",
      "下\n",
      "还\n",
      "出\n",
      "过\n",
      "地\n",
      "会\n",
      "道\n",
      "《临高启明》吹牛者\n",
      "\n",
      "严正声明：本书为丫丫小\n",
      "nb sequences: 9215292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9215292, 48), (9215292, 48))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use entire text\n",
    "text = open('./data/lgqm.txt').read()\n",
    "text = unicode(text, \"utf-8\")\n",
    "print('length of text: ', len(text), text[:100])\n",
    "charset = set(text)\n",
    "char_freq_map = {c: 0 for c in charset}\n",
    "for c in text:\n",
    "    char_freq_map[c] += 1\n",
    "char_freq_list = sorted(char_freq_map.items(), key=operator.itemgetter(1))\n",
    "char_freq_list.reverse()\n",
    "charlist = [pair[0] for pair in char_freq_list]\n",
    "print('size of charset', len(charlist))\n",
    "for i in range(40):\n",
    "    print(charlist[i])\n",
    "char2idx = dict((c, i) for i, c in enumerate(charlist))\n",
    "text_in_idx = [char2idx[c] for c in text]\n",
    "#text_in_idx[:24]\n",
    "print(''.join(charlist[i] for i in text_in_idx[:24]))\n",
    "maxlen = 48\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text_in_idx) - maxlen):\n",
    "    sentences.append(text_in_idx[i: i + maxlen])\n",
    "    next_chars.append(text_in_idx[i+1: i+maxlen+1])\n",
    "print('nb sequences:', len(sentences))\n",
    "sentences = np.array(sentences)\n",
    "next_chars = np.array(next_chars)\n",
    "sentences.shape, next_chars.shape\n",
    "print('xxx done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (64, 48, 200)         1137600     embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNormal(64, 48, 200)         400         embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (64, 48, 512)         1460224     batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (64, 48, 512)         0           lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (64, 48, 512)         2099200     dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (64, 48, 512)         0           lstm_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_3 (TimeDistribute(64, 48, 512)         262656      dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (64, 48, 512)         0           timedistributed_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_4 (TimeDistribute(64, 48, 5688)        2917944     dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 7878024\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_fac = 200\n",
    "batch_size = 64\n",
    "n_hidden = 512\n",
    "vocab_size = len(charlist)\n",
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=maxlen, batch_input_shape=(batch_size, maxlen)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(n_hidden, input_dim=n_fac,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        LSTM(n_hidden, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(n_hidden, activation='relu')),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7154944/9215232 [======================>.......] - ETA: 13255s - loss: 3.5622"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-9509fc0d8c05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-38254d8c0bed>\u001b[0m in \u001b[0;36mrun_epochs\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_truncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_chars_adjusted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mweight_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/text-generation-lgqm-ver-1-char-cnn-'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0mallow_gc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0m\u001b[1;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m    951\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_epochs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
