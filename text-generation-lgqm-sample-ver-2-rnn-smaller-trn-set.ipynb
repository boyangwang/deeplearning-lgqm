{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver 1 using char-cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano.sandbox import cuda\n",
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import TimeDistributed, Activation\n",
    "from numpy.random import choice\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\n",
    "from keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.regularizers import l2, activity_l2, l1, activity_l1\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils.layer_utils import layer_from_config\n",
    "from keras.metrics import categorical_crossentropy, categorical_accuracy\n",
    "from keras.layers.convolutional import *\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from numpy.random import choice\n",
    "import time\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text:  9215340\n",
      "《临高启明》吹牛者\n",
      "\n",
      "严正声明：本书为丫丫小说网(www.shuyaya.com)的用户上传至其在本站的存储空间，本站只提供TXT全集电子书存储服务以及免费下载服务，以下作品内容之版权与本站无任何\n",
      "size of charset 5688\n",
      " \n",
      "，\n",
      "的\n",
      "\n",
      "\n",
      "\n",
      "。\n",
      "是\n",
      "了\n",
      "一\n",
      "不\n",
      "“\n",
      "”\n",
      "这\n",
      "人\n",
      "有\n",
      "在\n",
      "他\n",
      "来\n",
      "个\n",
      "大\n",
      "上\n",
      "就\n",
      "得\n",
      "到\n",
      "要\n",
      "们\n",
      "和\n",
      "说\n",
      "里\n",
      "―\n",
      "也\n",
      "着\n",
      "子\n",
      "下\n",
      "还\n",
      "出\n",
      "过\n",
      "地\n",
      "会\n",
      "道\n",
      "《临高启明》吹牛者\n",
      "\n",
      "严正声明：本书为丫丫小\n",
      "nb sequences: 9215292\n",
      "xxx done\n"
     ]
    }
   ],
   "source": [
    "# use entire text\n",
    "text = open('./data/lgqm.txt').read()\n",
    "text = unicode(text, \"utf-8\")\n",
    "print('length of text: ', len(text))\n",
    "print(text[:100])\n",
    "charset = set(text)\n",
    "char_freq_map = {c: 0 for c in charset}\n",
    "for c in text:\n",
    "    char_freq_map[c] += 1\n",
    "char_freq_list = sorted(char_freq_map.items(), key=operator.itemgetter(1))\n",
    "char_freq_list.reverse()\n",
    "charlist = [pair[0] for pair in char_freq_list]\n",
    "print('size of charset', len(charlist))\n",
    "for i in range(40):\n",
    "    print(charlist[i])\n",
    "char2idx = dict((c, i) for i, c in enumerate(charlist))\n",
    "text_in_idx = [char2idx[c] for c in text]\n",
    "#text_in_idx[:24]\n",
    "print(''.join(charlist[i] for i in text_in_idx[:24]))\n",
    "maxlen = 48\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text_in_idx) - maxlen):\n",
    "    sentences.append(text_in_idx[i: i + maxlen])\n",
    "    next_chars.append(text_in_idx[i+1: i+maxlen+1])\n",
    "print('nb sequences:', len(sentences))\n",
    "sentences = np.array(sentences)\n",
    "next_chars = np.array(next_chars)\n",
    "sentences.shape, next_chars.shape\n",
    "print('xxx done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (64, 48, 100)         568800      embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNormal(64, 48, 100)         200         embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (64, 48, 128)         117248      batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (64, 48, 128)         0           lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (64, 48, 128)         131584      dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (64, 48, 128)         0           lstm_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_3 (TimeDistribute(64, 48, 128)         16512       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (64, 48, 128)         0           timedistributed_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_4 (TimeDistribute(64, 48, 5688)        733752      dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1568096\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_fac = 100\n",
    "batch_size = 64\n",
    "n_hidden = 128\n",
    "vocab_size = len(charlist)\n",
    "model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=maxlen, batch_input_shape=(batch_size, maxlen)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(n_hidden, input_dim=n_fac,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        LSTM(n_hidden, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(n_hidden, activation='relu')),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "model.summary()\n",
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epochs(n, trn_size=100):\n",
    "    # input must be exact multiples of batch_size, for stateful\n",
    "    # multiples = len(sentences)//batch_size*batch_size\n",
    "    # sentences_truncated = sentences[:multiples]\n",
    "    # next_chars_truncated = next_chars[:multiples]\n",
    "    next_chars_adjusted = np.expand_dims(next_chars,-1)\n",
    "    trn_size = batch_size * trn_size\n",
    "    rand_trn_idx = np.random.randint(0, high=len(text)-1-trn_size)\n",
    "    \n",
    "    sentences_selected = sentences[rand_trn_idx:rand_trn_idx+trn_size]\n",
    "    next_chars_selected = next_chars_adjusted[rand_trn_idx:rand_trn_idx+trn_size]\n",
    "    \n",
    "    for i in range(n):\n",
    "        rand_trn_idx = np.random.randint(0, high=len(text)-1-trn_size)\n",
    "    \n",
    "        sentences_selected = sentences[rand_trn_idx:rand_trn_idx+trn_size]\n",
    "        next_chars_selected = next_chars_adjusted[rand_trn_idx:rand_trn_idx+trn_size]\n",
    "        # model.reset_states()\n",
    "        h = model.fit(sentences_selected, next_chars_selected, batch_size=batch_size, nb_epoch=1, shuffle=True)\n",
    "        print(h.history, h.history['loss'])\n",
    "        weight_file_name = './data/text-generation-lgqm-ver-1-char-cnn-'+str(time.time())+'.h5'\n",
    "    model.save_weights(weight_file_name)\n",
    "    print('saved weights: ', weight_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: when cr is not together with lf, a line is biten! But, I doubt it ever happens in original text\n",
    "# Better learn more to let it avoid naturally\n",
    "\n",
    "def print_example_inline_seed_non_stateful():\n",
    "    pre_string = u\"第65535节 \"\n",
    "    \n",
    "    rand_idx = np.random.randint(0, high=len(text)-maxlen-1)\n",
    "    seed_string = text[rand_idx:rand_idx+maxlen]\n",
    "    \n",
    "    for i in range(maxlen+1):\n",
    "        x=np.array([char2idx[c] for c in seed_string[-maxlen:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(charlist, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    seed_string = pre_string+seed_string[maxlen:]\n",
    "    print(seed_string)\n",
    "    for i in range(3000):\n",
    "        x=np.array([char2idx[c] for c in seed_string[-maxlen:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(charlist, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print('final: ', seed_string)\n",
    "    return seed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.8163    \n",
      "{'loss': [4.8163385391235352]} [4.8163385391235352]\n",
      "saved weights:  ./data/text-generation-lgqm-ver-1-char-cnn-1497651144.43.h5\n"
     ]
    }
   ],
   "source": [
    "run_epochs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gen_text = print_example_inline_seed_non_stateful()\n",
    "f = codecs.open('./data/generated_text/generated_text_0.txt', encoding='utf-8', mode='w+')\n",
    "f.write(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.4430    \n",
      "{'loss': [4.4429683184623716]} [4.4429683184623716]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.0540    \n",
      "{'loss': [4.0539587378501896]} [4.0539587378501896]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.2122    \n",
      "{'loss': [4.2121559667587283]} [4.2121559667587283]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.3015    \n",
      "{'loss': [4.3014821171760556]} [4.3014821171760556]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.3117    \n",
      "{'loss': [4.3116943573951723]} [4.3116943573951723]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.1374    \n",
      "{'loss': [4.1373786377906798]} [4.1373786377906798]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.0418    \n",
      "{'loss': [4.0417818546295168]} [4.0417818546295168]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.0581    \n",
      "{'loss': [4.0581373882293699]} [4.0581373882293699]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.4531    \n",
      "{'loss': [4.4531126165390011]} [4.4531126165390011]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 3.9757    \n",
      "{'loss': [3.97566477060318]} [3.97566477060318]\n",
      "saved weights:  ./data/text-generation-lgqm-ver-1-char-cnn-1497651871.34.h5\n"
     ]
    }
   ],
   "source": [
    "run_epochs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text_n(n):\n",
    "    for i in range(n):\n",
    "        gen_text = print_example_inline_seed_non_stateful()\n",
    "        f = codecs.open('./data/generated_text/generated_text_'+str(time.time())+'.txt', encoding='utf-8', mode='w+')\n",
    "        f.write(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "64000/64000 [==============================] - 304s - loss: 3.8822   \n",
      "{'loss': [3.8822375457286835]} [3.8822375457286835]\n",
      "saved weights:  ./data/text-generation-lgqm-ver-1-char-cnn-1497652204.4.h5\n"
     ]
    }
   ],
   "source": [
    "run_epochs(1, trn_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第65535节 逃，在柜上门面“回来恶递给用好白，又是满小罩给。腹存也是米？”\n",
      "\n",
      "    正在先摆工。等难之想\n",
      "final:  第65535节 逃，在柜上门面“回来恶递给用好白，又是满小罩给。腹存也是米？”\n",
      "\n",
      "    正在先摆工。等难之想索支持，现在也是王四娘那么来往，就把房子也忙着同床，里面也没见过镇上没多。\n",
      "\n",
      "    这时候还忙在沈开宝算不必为奇了，她家借这件事。只要赈荒局夫妻做得，也不愿意自尽的慈惠堂子的，大小的真正备上白眼两便的态度有回到，还能勒过茶窗自然得开始道的变过。\n",
      "\n",
      "    “五月的小，没说到沈大人心里乡去不好得人才要收送家们自然看不上饱，只要船开所他还有来在字路上。桑梓的粮价工作就会议饭的“民变”用了！不活活不停得加上铺地，用大波了不是吹是些却走，这话赢得这人的官威让人手。自己诸意感觉的消息遇到她，出了赈济名船丝来借成把蚕农斗财力。因而没有三钱白的泥事烧不纳集河，这慈惠堂有一次，早为几的人的事情就是胡层方气的蚁不买去。还是村里几声儿再修之中，这还开始“糊箪纸”的无息地，还是眼睛少少按照三十一些的至于生丝的行情，多多娘在新叶以沈大门里相的耕牛了。情必然是要面\n",
      "\n",
      "    “谁说该蚕桑户的花俏做有这溪水箪”，杭州府有十石叶，二庆都是害怕；我不显收不了饿。这些个人士，让家里都发觉火，自己便是镇上流民一番立刻引起了杂粮。\n",
      "\n",
      "    赵引弓说道，“怎么想移气”她一块，沈大听说是一天只能祈了这个税赋，他到了善后局的余杭缙绅，但是具体行理愈发动重。催青不认化怕孵化。更是船上无狈二代利。村民很大，公私两便还是重视怕当差，地方小民没一时，慈惠堂的活动力粗是糊箪纸，村女人也推开了，能到现在也是块傍“大片，特别是熟货”的期望食，但是有心景就闭不可旦了。所以丝茧行，还能在座难民流民一概在大伙子为任何。大伙都没错一挺。如今就不愿意多少人社开阔话。\n",
      "\n",
      "    王四娘已经说说得，大伙都有点明感解的育种商一次灾荒不予过了的秀才。虽然是在王四娘家里是个次人工作的事情。\n",
      "\n",
      "    不过到了这些方案数字似乎给这么不是干净了，用得棚田人绝不有奇气，特别是这么多久，大伙都没一人家，他们心存过面。“谁意光了。”\n",
      "\n",
      "    这事话和蚕花熟示不错。”沈开宝笙嗽了回茶，端起了吹嘘了一番。沈开宝心道道远并不敢建重而已。\n",
      "\n",
      "    沈开宝王四娘家的债才会出褡极已经出去。必然这次至于十月”――她不知道沈开宝这些土纸下咽功方呢：好歹有天年，要在本地一件精神都没有肚子的风影，不接看着多少活动。湖州开展的炊烟是个装着纱里，个农户上的把官儿的地方上店，专门此事就能不体常官了，不贵人在河里还大了一阵不可就显示不敢通施，不见得消息的几个帮助了，他不瞧着听得农户要需要穷门发了。\n",
      "\n",
      "    “可能是太快，借债丝茧买出来了一张银子，为收购来得作胜了，这都可谓大眼话，正好赵引弓引起多少，不用得到糖前界，连带着这些你戚房卖得去东西的水庙，拿买蚕桑户也会在外来去烤干的先保的开展屋，又没人觉得十分低下来。程中的慈惠堂依然是满意，一律，就不让过来的事情，特别是没多久。你又将知道带着债，有来看蚕桑户也挤心气，也不长说，这时候就有三乡家在本息的。从座不误十几盏子。活动：部分难需自足关系，救灾当地和仁荒倍征不知题剥“迫方太低。”\n",
      "\n",
      "    王四娘此若远了。\n",
      "\n",
      "    至于自己留五张布子就是让刘梦谦色上的背景，在也是吃宠指望灾的提醒这位沈大伙原本为其用虚平比当然计较的泥块，买到大约能在付伤。\n",
      "\n",
      "    这倒是自己出面的啧啧扬息，她觉得也在那些人要开始给她借唬着“蚕箪”的轰动，远响力――用力都会立刻有活慨。沈开宝绝非是办得。其他各种行情了。白糟房上有女人，纵然有二亩桑树，具体还是村里们已经被一起来了。总之同的免起秋身下咽――自然几天间还会闻，即来赵引弓还是大变”了。\n",
      "\n",
      "    这个拿好的新叶还在忙卖得活给这笔，早就配饿种人家，扶个官兵又是养蚕规模，个桑叶已经过发功的育行情。但是具体开始就一种机会。\n",
      "\n",
      "    原本是好的农具来了。只要没意到沈开宝教育救灾的地方上的很亏的宅基地赋租店征暴敛的声青社员递河一孵――全是有年要运气油艺要出手偿还的压榨出来。\n",
      "\n",
      "    “烧得男酸？”沈开宝提出一起出了一顿顿顿顿顿治里的去自己那么绿色。\n",
      "\n",
      "    她觉得对这样的官儿们之后的养蚕刀、血块外几天也隐隐约约成一个酸，代客也让方式青灰，已经发出布子。\n",
      "\n",
      "    借债工作不同，忍还让原本是一年的“时候，皇民摇船烧扬白的后院就好求钱都是这么抬杠，特意有很高流民是沈大听说做得。不算杭州城里，没为天暇。\n",
      "\n",
      "    刘梦谦来得王四娘家做什么那两夫，缫丝的业务人物了。难民关系太难民。\n",
      "\n",
      "    没肉点一句，有点生丝时候，在村里中还是委员还要能在自己灯都直奔以态度或者自己托村里，和花花之后贪走很大的气氛红只有十天工作人厚。\n",
      "\n",
      "    “大小的蚕宝只要三十斤大量客，这会行情的样子。\n",
      "\n",
      "    “所以一干，现在你们想出来。”赵引弓一点。\n",
      "\n",
      "    这对人说。\n",
      "\n",
      "    大伙都不闻了，据说是王四娘每天已经放过了点。总是蚕农们给这个花纸。来得“度荒的秀才这位看出入钱。不过这个时候，不断是他们散去的宠，原本连猪的胆子都会自己缫丝的不同床，只能种往杭州知府，这话养蚕的收益难民要养蚕了清明不少的。\n",
      "\n",
      "    沈大家借债价格许多转视，孵该给丝茧行会来这位欠下把做出出来了！没米价格价活决了，便不但这思就不管干净，浪费借债还敢派的农户。\n",
      "\n",
      "    因而这件事不少少的感觉放个记发理决等“聚下去”上恶煞薪，他顺手，本地的原本真是天绿之士。平均在冀图几家赵引弓觉得万石，难可被赈济来还能不会有了。总去人一种月等老婆恐怕是用去。\n",
      "\n",
      "    他的身上往年相熟。的女人忙几匹前不接，遇到经办人如今只有个仙蚕，湖州当管，实际暂时消失是“更容易既然代赈”的何厚，孙淳弄不到拉开办理不是不起。但是别说是硬糖的脸皮，连一定的写得实际宜成价了，也没有耐处――谁有人嘴摇着。\n",
      "\n",
      "    没想到这件事。家里的种子之后都隐隐体子阴募都快味了一步！沈大家的钱米。是村里都突然，所谓想借一次已经抵押给收益什么隐患。这知府最是他莫罗中使丝茧上投无音。总把镇上众女儿和人家的缙绅的钱粮之士。赵引弓越伙用到窝笼络。\n",
      "\n",
      "    开始勒董，一路没有烤干，一双影没出嫁的流民们有米――她很快是公好顶，身上的事情说。看着也要和银子这当得到收一起然收购的境界――村里，一点印的眉飞，种桑地方小是官，他有什么是赚点他们，实际不已会，也有报纸的养蚕缫丝灾民委员目中当了“身子”！\n",
      "\n",
      "    也没有这么奇。\n",
      "\n",
      "    赵引弓在感逼。现在这个时候就倒让这些十分名做买几匹稍能去。”\n",
      "\n",
      "    不过“蚕箪”虽然说，流民的影响力分这次在灭目消化的米难之。至于早说看到这又是让沈开宝声音一个酸儿家都一两，不要再出来，但是在时候为大庆媳妇又好茶的时候，很好的屋勤营主表树白的东西。只是沈开宝家从吹嘘一顿舒展出力。只要这次开始湖州省的暴露了。刘梦谦关照一位孩子们都顺手的加解。正是曹老爷的杭州河塘江南知道，是他的船上的转视沽透。\n",
      "\n",
      "    沈大家的‘事情会肯干买一副，讨粒发了自己三次掌柜靠这样：在博上印天，很坏全让丈夫层层所候倒宜扎的地方生活，虽然已经是胡编叶，那么这种大事。这里的事情全村的店村那个钱粮则是满意的摇船，何士低下得东西，把纵然这些坐生问题。一定设田。不由得人得房子。\n",
      "\n",
      "    经办冷热，说她，连称什\n",
      "第65535节 未以要货款托石灰，基本倒要开始给曹老爷帮着开始大量作要被人教得东西久违――原本就是难以进工和慈幼兄\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    generate_text_n(20)\n",
    "    run_epochs(4, trn_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
