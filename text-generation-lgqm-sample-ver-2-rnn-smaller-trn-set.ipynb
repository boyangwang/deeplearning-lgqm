{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver 1 using char-cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano.sandbox import cuda\n",
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import TimeDistributed, Activation\n",
    "from numpy.random import choice\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional\n",
    "from keras.layers import TimeDistributed, Activation, SimpleRNN, GRU\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.regularizers import l2, activity_l2, l1, activity_l1\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils.layer_utils import layer_from_config\n",
    "from keras.metrics import categorical_crossentropy, categorical_accuracy\n",
    "from keras.layers.convolutional import *\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from numpy.random import choice\n",
    "import time\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text:  9215340\n",
      "《临高启明》吹牛者\n",
      "\n",
      "严正声明：本书为丫丫小说网(www.shuyaya.com)的用户上传至其在本站的存储空间，本站只提供TXT全集电子书存储服务以及免费下载服务，以下作品内容之版权与本站无任何\n",
      "size of charset 5688\n",
      " \n",
      "，\n",
      "的\n",
      "\n",
      "\n",
      "\n",
      "。\n",
      "是\n",
      "了\n",
      "一\n",
      "不\n",
      "“\n",
      "”\n",
      "这\n",
      "人\n",
      "有\n",
      "在\n",
      "他\n",
      "来\n",
      "个\n",
      "大\n",
      "上\n",
      "就\n",
      "得\n",
      "到\n",
      "要\n",
      "们\n",
      "和\n",
      "说\n",
      "里\n",
      "―\n",
      "也\n",
      "着\n",
      "子\n",
      "下\n",
      "还\n",
      "出\n",
      "过\n",
      "地\n",
      "会\n",
      "道\n",
      "《临高启明》吹牛者\n",
      "\n",
      "严正声明：本书为丫丫小\n",
      "nb sequences: 9215292\n",
      "xxx done\n"
     ]
    }
   ],
   "source": [
    "# use entire text\n",
    "text = open('./data/lgqm.txt').read()\n",
    "text = unicode(text, \"utf-8\")\n",
    "print('length of text: ', len(text))\n",
    "print(text[:100])\n",
    "charset = set(text)\n",
    "char_freq_map = {c: 0 for c in charset}\n",
    "for c in text:\n",
    "    char_freq_map[c] += 1\n",
    "char_freq_list = sorted(char_freq_map.items(), key=operator.itemgetter(1))\n",
    "char_freq_list.reverse()\n",
    "charlist = [pair[0] for pair in char_freq_list]\n",
    "print('size of charset', len(charlist))\n",
    "for i in range(40):\n",
    "    print(charlist[i])\n",
    "char2idx = dict((c, i) for i, c in enumerate(charlist))\n",
    "text_in_idx = [char2idx[c] for c in text]\n",
    "#text_in_idx[:24]\n",
    "print(''.join(charlist[i] for i in text_in_idx[:24]))\n",
    "maxlen = 48\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text_in_idx) - maxlen):\n",
    "    sentences.append(text_in_idx[i: i + maxlen])\n",
    "    next_chars.append(text_in_idx[i+1: i+maxlen+1])\n",
    "print('nb sequences:', len(sentences))\n",
    "sentences = np.array(sentences)\n",
    "next_chars = np.array(next_chars)\n",
    "sentences.shape, next_chars.shape\n",
    "print('xxx done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (64, 48, 100)         568800      embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNormal(64, 48, 100)         200         embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (64, 48, 128)         117248      batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (64, 48, 128)         0           lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (64, 48, 128)         131584      dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (64, 48, 128)         0           lstm_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_3 (TimeDistribute(64, 48, 128)         16512       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (64, 48, 128)         0           timedistributed_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_4 (TimeDistribute(64, 48, 5688)        733752      dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1568096\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_fac = 100\n",
    "batch_size = 64\n",
    "n_hidden = 128\n",
    "vocab_size = len(charlist)\n",
    "model = Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=maxlen, batch_input_shape=(batch_size, maxlen)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(n_hidden, input_dim=n_fac,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        LSTM(n_hidden, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(n_hidden, activation='relu')),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "model.summary()\n",
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epochs(n, trn_size=100):\n",
    "    # input must be exact multiples of batch_size, for stateful\n",
    "    # multiples = len(sentences)//batch_size*batch_size\n",
    "    # sentences_truncated = sentences[:multiples]\n",
    "    # next_chars_truncated = next_chars[:multiples]\n",
    "    next_chars_adjusted = np.expand_dims(next_chars,-1)\n",
    "    trn_size = batch_size * trn_size\n",
    "    rand_trn_idx = np.random.randint(0, high=len(text)-1-trn_size)\n",
    "    \n",
    "    sentences_selected = sentences[rand_trn_idx:rand_trn_idx+trn_size]\n",
    "    next_chars_selected = next_chars_adjusted[rand_trn_idx:rand_trn_idx+trn_size]\n",
    "    \n",
    "    for i in range(n):\n",
    "        rand_trn_idx = np.random.randint(0, high=len(text)-1-trn_size)\n",
    "    \n",
    "        sentences_selected = sentences[rand_trn_idx:rand_trn_idx+trn_size]\n",
    "        next_chars_selected = next_chars_adjusted[rand_trn_idx:rand_trn_idx+trn_size]\n",
    "        # model.reset_states()\n",
    "        h = model.fit(sentences_selected, next_chars_selected, batch_size=batch_size, nb_epoch=1, shuffle=True)\n",
    "        print(h.history, h.history['loss'])\n",
    "        weight_file_name = './data/text-generation-lgqm-ver-1-char-cnn-'+str(time.time())+'.h5'\n",
    "    model.save_weights(weight_file_name)\n",
    "    print('saved weights: ', weight_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: when cr is not together with lf, a line is biten! But, I doubt it ever happens in original text\n",
    "# Better learn more to let it avoid naturally\n",
    "\n",
    "def print_example_inline_seed_non_stateful():\n",
    "    pre_string = u\"第65535节 \"\n",
    "    \n",
    "    rand_idx = np.random.randint(0, high=len(text)-maxlen-1)\n",
    "    seed_string = text[rand_idx:rand_idx+maxlen]\n",
    "    \n",
    "    for i in range(maxlen+1):\n",
    "        x=np.array([char2idx[c] for c in seed_string[-maxlen:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(charlist, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    seed_string = pre_string+seed_string[maxlen:]\n",
    "    print(seed_string)\n",
    "    for i in range(3000):\n",
    "        x=np.array([char2idx[c] for c in seed_string[-maxlen:]])[np.newaxis,:]\n",
    "        preds = model.predict(x, verbose=0)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(charlist, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print('final: ', seed_string)\n",
    "    return seed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.8163    \n",
      "{'loss': [4.8163385391235352]} [4.8163385391235352]\n",
      "saved weights:  ./data/text-generation-lgqm-ver-1-char-cnn-1497651144.43.h5\n"
     ]
    }
   ],
   "source": [
    "run_epochs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gen_text = print_example_inline_seed_non_stateful()\n",
    "f = codecs.open('./data/generated_text/generated_text_0.txt', encoding='utf-8', mode='w+')\n",
    "f.write(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.4430    \n",
      "{'loss': [4.4429683184623716]} [4.4429683184623716]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.0540    \n",
      "{'loss': [4.0539587378501896]} [4.0539587378501896]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.2122    \n",
      "{'loss': [4.2121559667587283]} [4.2121559667587283]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.3015    \n",
      "{'loss': [4.3014821171760556]} [4.3014821171760556]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.3117    \n",
      "{'loss': [4.3116943573951723]} [4.3116943573951723]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.1374    \n",
      "{'loss': [4.1373786377906798]} [4.1373786377906798]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.0418    \n",
      "{'loss': [4.0417818546295168]} [4.0417818546295168]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.0581    \n",
      "{'loss': [4.0581373882293699]} [4.0581373882293699]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 4.4531    \n",
      "{'loss': [4.4531126165390011]} [4.4531126165390011]\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 30s - loss: 3.9757    \n",
      "{'loss': [3.97566477060318]} [3.97566477060318]\n",
      "saved weights:  ./data/text-generation-lgqm-ver-1-char-cnn-1497651871.34.h5\n"
     ]
    }
   ],
   "source": [
    "run_epochs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text_n(n):\n",
    "    for i in range(n):\n",
    "        gen_text = print_example_inline_seed_non_stateful()\n",
    "        f = codecs.open('./data/generated_text/generated_text_'+str(time.time())+'.txt', encoding='utf-8', mode='w+')\n",
    "        f.write(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "64000/64000 [==============================] - 304s - loss: 3.8822   \n",
      "{'loss': [3.8822375457286835]} [3.8822375457286835]\n",
      "saved weights:  ./data/text-generation-lgqm-ver-1-char-cnn-1497652204.4.h5\n"
     ]
    }
   ],
   "source": [
    "run_epochs(1, trn_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第65535节 工作队，对武鸣的想了――如今是官举不清，全部倒有“一名澳洲人送来如此了。”\r\n",
      "\r\n",
      "    现在”\r\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    generate_text_n(50)\n",
    "    run_epochs(4, trn_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
